{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9950437,"sourceType":"datasetVersion","datasetId":6119213},{"sourceId":9950893,"sourceType":"datasetVersion","datasetId":6119545},{"sourceId":9953763,"sourceType":"datasetVersion","datasetId":6121659},{"sourceId":10073078,"sourceType":"datasetVersion","datasetId":6208884}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import googleapiclient.discovery\nimport pandas as pd\n\napi_service_name = \"youtube\"\napi_version = \"v3\"\nDEVELOPER_KEY = \"AIzaSyArF1N6qMdgiWUogt0A9LfX1BjEyc-Uqc0\"\n\nyoutube = googleapiclient.discovery.build(\n    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n\n\ndef getcomments(video):\n  request = youtube.commentThreads().list(\n      part=\"snippet\",\n      videoId=video,\n      maxResults=100\n  )\n\n  comments = []\n\n  # Execute the request.\n  response = request.execute()\n\n  # Get the comments from the response.\n  for item in response['items']:\n      comment = item['snippet']['topLevelComment']['snippet']\n      comments.append([\n          comment['authorDisplayName'],\n          comment['updatedAt'],\n          comment['publishedAt'],\n          comment['likeCount'],\n          comment['textOriginal']\n\n      ])\n\n  while (1 == 1):\n    try:\n     nextPageToken = response['nextPageToken']\n    except KeyError:\n     break\n    nextPageToken = response['nextPageToken']\n    # Create a new request object with the next page token.\n    nextRequest = youtube.commentThreads().list(part=\"snippet\", videoId=video, maxResults=100, pageToken=nextPageToken)\n    # Execute the next request.\n    response = nextRequest.execute()\n    # Get the comments from the next response.\n    for item in response['items']:\n      comment = item['snippet']['topLevelComment']['snippet']\n      comments.append([\n          comment['authorDisplayName'],\n          comment['updatedAt'],\n          comment['publishedAt'],\n          comment['likeCount'],\n          comment['textOriginal']\n      ])\n\n  df2 = pd.DataFrame(comments, columns=['author', 'updated_at','publishedAt', 'like_count', 'text'])\n  return df2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T04:39:16.021568Z","iopub.execute_input":"2024-11-19T04:39:16.021987Z","iopub.status.idle":"2024-11-19T04:39:16.905905Z","shell.execute_reply.started":"2024-11-19T04:39:16.021929Z","shell.execute_reply":"2024-11-19T04:39:16.904739Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\ndf = pd.DataFrame()\nfor i in ['rZMjejYaREE','tYlTzyDnqP4','FDZv28KJZiU','2cpeuv8HbxU','pQlAZn6-syk','IEs1RVQb9TY','fF5uGf1_3iM','Hyj65VbkRcU','sBEAh-yO6e8','zlvZDd5q3-Y','IrDWAVei-mU','CSdJq0d900k','MDH3tiiAki0','pR7X6fSyQp8','W7NbRCs2fdc','wGBbCAbLjus','BuRPEv7rUcI','x1C5-weRAcA','bqHtKYPC1KQ','FToNGQPzGEQ','uX7xsHsmSSo']:\n  df2 = getcomments(i)\n  df = pd.concat([df, df2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T04:39:16.907770Z","iopub.execute_input":"2024-11-19T04:39:16.908170Z","iopub.status.idle":"2024-11-19T04:42:38.294523Z","shell.execute_reply.started":"2024-11-19T04:39:16.908137Z","shell.execute_reply":"2024-11-19T04:42:38.293359Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T04:42:38.295840Z","iopub.execute_input":"2024-11-19T04:42:38.296202Z","iopub.status.idle":"2024-11-19T04:42:38.317020Z","shell.execute_reply.started":"2024-11-19T04:42:38.296170Z","shell.execute_reply":"2024-11-19T04:42:38.315879Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"              author            updated_at           publishedAt  like_count  \\\n0        @munmun9892  2024-10-28T03:35:19Z  2024-10-28T03:35:19Z           0   \n1        @munmun9892  2024-10-28T03:34:37Z  2024-10-28T03:34:37Z           0   \n2  @Prathvivarankhen  2024-08-21T14:50:31Z  2024-08-21T14:50:31Z           0   \n3      @dreamaim6891  2024-07-02T16:31:10Z  2024-07-02T16:31:10Z           0   \n4    @SakshamJha-b8j  2024-07-02T13:03:47Z  2024-07-02T13:03:47Z           0   \n\n                                                text  \n0      God's blessingsüôèüôèüôèüôèüôè is always withüòäüòäüòäüòä you..  \n1  Congratulationsüéâü•≥ü•≥üëèüëè\\nMr. Modiji... \\nAnd othe...  \n2               ‡§á‡§∏ ‡§ú‡•Å‡§Æ‡§≤‡•á ‡§¨‡§æ‡§ú ‡§ï‡•ã ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Ü‡§§‡•Ä ‡§π‡•Ä ‡§® ‡§π‡•à  \n3         Lier. He Don't keep his oath. A false man.  \n4  Abb ye desh barbadi ke ke raste pe chal diya h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>updated_at</th>\n      <th>publishedAt</th>\n      <th>like_count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@munmun9892</td>\n      <td>2024-10-28T03:35:19Z</td>\n      <td>2024-10-28T03:35:19Z</td>\n      <td>0</td>\n      <td>God's blessingsüôèüôèüôèüôèüôè is always withüòäüòäüòäüòä you..</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@munmun9892</td>\n      <td>2024-10-28T03:34:37Z</td>\n      <td>2024-10-28T03:34:37Z</td>\n      <td>0</td>\n      <td>Congratulationsüéâü•≥ü•≥üëèüëè\\nMr. Modiji... \\nAnd othe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Prathvivarankhen</td>\n      <td>2024-08-21T14:50:31Z</td>\n      <td>2024-08-21T14:50:31Z</td>\n      <td>0</td>\n      <td>‡§á‡§∏ ‡§ú‡•Å‡§Æ‡§≤‡•á ‡§¨‡§æ‡§ú ‡§ï‡•ã ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Ü‡§§‡•Ä ‡§π‡•Ä ‡§® ‡§π‡•à</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@dreamaim6891</td>\n      <td>2024-07-02T16:31:10Z</td>\n      <td>2024-07-02T16:31:10Z</td>\n      <td>0</td>\n      <td>Lier. He Don't keep his oath. A false man.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SakshamJha-b8j</td>\n      <td>2024-07-02T13:03:47Z</td>\n      <td>2024-07-02T13:03:47Z</td>\n      <td>0</td>\n      <td>Abb ye desh barbadi ke ke raste pe chal diya h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T04:42:38.319380Z","iopub.execute_input":"2024-11-19T04:42:38.319718Z","iopub.status.idle":"2024-11-19T04:42:38.325676Z","shell.execute_reply.started":"2024-11-19T04:42:38.319682Z","shell.execute_reply":"2024-11-19T04:42:38.324580Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(90782, 5)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Save the DataFrame to an Excel file in the working directory\ndf.to_excel('/kaggle/working/output.xlsx', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T04:45:48.823314Z","iopub.execute_input":"2024-11-19T04:45:48.823741Z","iopub.status.idle":"2024-11-19T04:46:00.267490Z","shell.execute_reply.started":"2024-11-19T04:45:48.823705Z","shell.execute_reply":"2024-11-19T04:46:00.266304Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"AIzaSyArF1N6qMdgiWUogt0A9LfX1BjEyc-Uqc0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pandas google-api-python-client\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:03:55.224506Z","iopub.execute_input":"2024-11-19T10:03:55.224889Z","iopub.status.idle":"2024-11-19T10:04:07.223092Z","shell.execute_reply.started":"2024-11-19T10:03:55.224840Z","shell.execute_reply":"2024-11-19T10:04:07.221810Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (2.147.0)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (0.21.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (2.30.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (2.11.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (3.0.1)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.1)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom googleapiclient import discovery\nimport json\nimport time\n\n# API Key\nAPI_KEY = 'AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw'\n\n# Build the Perspective API client\nclient = discovery.build(\n    \"commentanalyzer\",\n    \"v1alpha1\",\n    developerKey=API_KEY,\n    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n    static_discovery=False,\n)\n\n# Function to get toxicity score\ndef get_toxicity_score(text):\n    try:\n        analyze_request = {\n            'comment': {'text': text},\n            'requestedAttributes': {'TOXICITY': {}}\n        }\n        response = client.comments().analyze(body=analyze_request).execute()\n        # Extract the toxicity score\n        score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n        return score\n    except Exception as e:\n        print(f\"Error analyzing text: {text}\\n{e}\")\n        return None\n\n# Function to classify text as 'hate' or 'not hate'\ndef classify_text(score, threshold=0.5):\n    if score is None:\n        return \"unknown\"\n    return \"hate\" if score >= threshold else \"not hate\"\n\n# Load CSV file\ninput_csv = \"/kaggle/input/englsihsdata/englishdata - Sheet1.csv\"  # Replace with your input file name\noutput_csv = \"/kaggle/working/output_comments2.csv\"  # Replace with your desired output file name\n\ndf = pd.read_csv(input_csv)\n\n# Ensure 'text' column exists\nif 'text' not in df.columns:\n    raise ValueError(\"The input CSV file must contain a 'text' column.\")\n\n# Analyze and classify comments\ntoxicity_scores = []\nlabels = []\n\nfor index, row in df.iterrows():\n    text = row['text']\n    score = get_toxicity_score(text)\n    toxicity_scores.append(score)\n    labels.append(classify_text(score))\n    time.sleep(1)  # Introduce a 1-second delay to respect the QPS limit\n\n# Add results to DataFrame\ndf['toxicity_score'] = toxicity_scores\ndf['label'] = labels\n\n# Save the annotated CSV file\ndf.to_csv(output_csv, index=False)\n\nprint(f\"Processed comments saved to {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:50:29.230730Z","iopub.execute_input":"2024-11-19T10:50:29.231081Z","iopub.status.idle":"2024-11-19T10:51:24.355088Z","shell.execute_reply.started":"2024-11-19T10:50:29.231052Z","shell.execute_reply":"2024-11-19T10:51:24.353997Z"}},"outputs":[{"name":"stdout","text":"Processed comments saved to /kaggle/working/output_comments2.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom googleapiclient import discovery\nimport json\nimport time\n\n# API Key\nAPI_KEY = 'AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw'\n\n# Build the Perspective API client\nclient = discovery.build(\n    \"commentanalyzer\",\n    \"v1alpha1\",\n    developerKey=API_KEY,\n    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n    static_discovery=False,\n)\n\n# Function to get toxicity score\ndef get_toxicity_score(text):\n    try:\n        analyze_request = {\n            'comment': {'text': text},\n            'requestedAttributes': {'TOXICITY': {}}\n        }\n        response = client.comments().analyze(body=analyze_request).execute()\n        # Extract the toxicity score\n        score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n        return score\n    except Exception as e:\n        print(f\"Error analyzing text: {text}\\n{e}\")\n        return None\n\n# Function to classify text as 'hate' or 'not hate'\ndef classify_text(score, threshold=0.5):\n    if score is None:\n        return \"unknown\"\n    return \"hate\" if score >= threshold else \"not hate\"\n\n# Load CSV file\ninput_csv = \"/kaggle/input/hiindi/hinditext - Sheet1.csv\"  # Replace with your input file name\noutput_csv = \"/kaggle/working/hindi_comments2.csv\"  # Replace with your desired output file name\n\ndf = pd.read_csv(input_csv)\n\n# Ensure 'text' column exists\nif 'text' not in df.columns:\n    raise ValueError(\"The input CSV file must contain a 'text' column.\")\n\n# Analyze and classify comments\ntoxicity_scores = []\nlabels = []\n\nfor index, row in df.iterrows():\n    text = row['text']\n    score = get_toxicity_score(text)\n    toxicity_scores.append(score)\n    labels.append(classify_text(score))\n    time.sleep(1)  # Introduce a 1-second delay to respect the QPS limit\n\n# Add results to DataFrame\ndf['toxicity_score'] = toxicity_scores\ndf['label'] = labels\n\n# Save the annotated CSV file\ndf.to_csv(output_csv, index=False)\n\nprint(f\"Processed comments saved to {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:56:05.262280Z","iopub.execute_input":"2024-11-19T10:56:05.262706Z","iopub.status.idle":"2024-11-19T10:57:04.568548Z","shell.execute_reply.started":"2024-11-19T10:56:05.262637Z","shell.execute_reply":"2024-11-19T10:57:04.567483Z"}},"outputs":[{"name":"stdout","text":"Error analyzing text: ‡§Æ‡•ã‡§¶‡•Ä ‡§ú‡§æ‡§ó‡§æ ‡§ó‡•Å‡§ú‡§∞‡§æ‡§§\n<HttpError 400 when requesting https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw&alt=json returned \"Attribute TOXICITY does not support request languages: mr\". Details: \"[{'@type': 'type.googleapis.com/google.commentanalyzer.v1alpha1.Error', 'errorType': 'LANGUAGE_NOT_SUPPORTED_BY_ATTRIBUTE', 'languageNotSupportedByAttributeError': {'detectedLanguages': ['mr'], 'attribute': 'TOXICITY'}}]\">\nProcessed comments saved to /kaggle/working/hindi_comments2.csv\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom googleapiclient import discovery\nimport json\nimport time\n\n# API Key\nAPI_KEY = 'AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw'\n\n# Build the Perspective API client\nclient = discovery.build(\n    \"commentanalyzer\",\n    \"v1alpha1\",\n    developerKey=API_KEY,\n    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n    static_discovery=False,\n)\n\n# Function to get toxicity score\ndef get_toxicity_score(text):\n    try:\n        analyze_request = {\n            'comment': {'text': text},\n            'requestedAttributes': {'TOXICITY': {}}\n        }\n        response = client.comments().analyze(body=analyze_request).execute()\n        # Extract the toxicity score\n        score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n        return score\n    except Exception as e:\n        print(f\"Error analyzing text: {text}\\n{e}\")\n        return None\n\n# Function to classify text as 'hate' or 'not hate'\ndef classify_text(score, threshold=0.5):\n    if score is None:\n        return \"unknown\"\n    return \"hate\" if score >= threshold else \"not hate\"\n\n# Load CSV file\ninput_csv = \"/kaggle/input/hinglishhh/hinglish - Sheet1.csv\"  # Replace with your input file name\noutput_csv = \"/kaggle/working/hinglish_comments2.csv\"  # Replace with your desired output file name\n\ndf = pd.read_csv(input_csv)\n\n# Ensure 'text' column exists\nif 'text' not in df.columns:\n    raise ValueError(\"The input CSV file must contain a 'text' column.\")\n\n# Analyze and classify comments\ntoxicity_scores = []\nlabels = []\n\nfor index, row in df.iterrows():\n    text = row['text']\n    score = get_toxicity_score(text)\n    toxicity_scores.append(score)\n    labels.append(classify_text(score))\n    time.sleep(1)  # Introduce a 1-second delay to respect the QPS limit\n\n# Add results to DataFrame\ndf['toxicity_score'] = toxicity_scores\ndf['label'] = labels\n\n# Save the annotated CSV file\ndf.to_csv(output_csv, index=False)\n\nprint(f\"Processed comments saved to {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T16:10:29.921873Z","iopub.execute_input":"2024-11-19T16:10:29.922278Z","iopub.status.idle":"2024-11-19T16:11:28.346177Z","shell.execute_reply.started":"2024-11-19T16:10:29.922230Z","shell.execute_reply":"2024-11-19T16:11:28.344488Z"}},"outputs":[{"name":"stdout","text":"Error analyzing text: RAHUL GANDI MI JHUKAGA NI SALAAAA\n<HttpError 400 when requesting https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw&alt=json returned \"Attribute TOXICITY does not support request languages: mr-Latn\". Details: \"[{'@type': 'type.googleapis.com/google.commentanalyzer.v1alpha1.Error', 'errorType': 'LANGUAGE_NOT_SUPPORTED_BY_ATTRIBUTE', 'languageNotSupportedByAttributeError': {'detectedLanguages': ['mr-Latn'], 'attribute': 'TOXICITY'}}]\">\nError analyzing text: Are Tu harega Modi abaki barüòÇ\n<HttpError 400 when requesting https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw&alt=json returned \"Attribute TOXICITY does not support request languages: kn-Latn\". Details: \"[{'@type': 'type.googleapis.com/google.commentanalyzer.v1alpha1.Error', 'errorType': 'LANGUAGE_NOT_SUPPORTED_BY_ATTRIBUTE', 'languageNotSupportedByAttributeError': {'detectedLanguages': ['kn-Latn'], 'attribute': 'TOXICITY'}}]\">\nError analyzing text: Tu gate pagala parika gapuchu kie bujhiba be\n<HttpError 400 when requesting https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw&alt=json returned \"Attribute TOXICITY does not support request languages: mr-Latn\". Details: \"[{'@type': 'type.googleapis.com/google.commentanalyzer.v1alpha1.Error', 'errorType': 'LANGUAGE_NOT_SUPPORTED_BY_ATTRIBUTE', 'languageNotSupportedByAttributeError': {'detectedLanguages': ['mr-Latn'], 'attribute': 'TOXICITY'}}]\">\nError analyzing text: Chal hatt baju hatt hawa ane de\n<HttpError 400 when requesting https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw&alt=json returned \"Attribute TOXICITY does not support request languages: gu-Latn\". Details: \"[{'@type': 'type.googleapis.com/google.commentanalyzer.v1alpha1.Error', 'errorType': 'LANGUAGE_NOT_SUPPORTED_BY_ATTRIBUTE', 'languageNotSupportedByAttributeError': {'detectedLanguages': ['gu-Latn'], 'attribute': 'TOXICITY'}}]\">\nProcessed comments saved to /kaggle/working/hinglish_comments2.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom googleapiclient import discovery\nimport json\nimport time\n\n# API Key\nAPI_KEY = 'AIzaSyAkiuDVwqcDmd7z-8Bi68fA6ck2u6cMSmw'\n\n# Build the Perspective API client\nclient = discovery.build(\n    \"commentanalyzer\",\n    \"v1alpha1\",\n    developerKey=API_KEY,\n    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n    static_discovery=False,\n)\n\n# Function to get toxicity score\ndef get_toxicity_score(text):\n    try:\n        analyze_request = {\n            'comment': {'text': text},\n            'requestedAttributes': {'TOXICITY': {}}\n        }\n        response = client.comments().analyze(body=analyze_request).execute()\n        # Extract the toxicity score\n        score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n        return score\n    except Exception as e:\n        print(f\"Error analyzing text: {text}\\n{e}\")\n        return None\n\n# Function to classify text as 'hate' or 'not hate'\ndef classify_text(score, threshold=0.5):\n    if score is None:\n        return \"unknown\"\n    return \"hate\" if score >= threshold else \"not hate\"\n\n# Load CSV file\ninput_csv = \"/kaggle/input/translated/translated - Sheet1.csv\"  # Replace with your input file name\noutput_csv = \"/kaggle/working/TRANSLATED_comments2.csv\"  # Replace with your desired output file name\n\ndf = pd.read_csv(input_csv)\n\n# Ensure 'text' column exists\nif 'text' not in df.columns:\n    raise ValueError(\"The input CSV file must contain a 'text' column.\")\n\n# Analyze and classify comments\ntoxicity_scores = []\nlabels = []\n\nfor index, row in df.iterrows():\n    text = row['text']\n    score = get_toxicity_score(text)\n    toxicity_scores.append(score)\n    labels.append(classify_text(score))\n    time.sleep(1)  # Introduce a 1-second delay to respect the QPS limit\n\n# Add results to DataFrame\ndf['toxicity_score'] = toxicity_scores\ndf['label'] = labels\n\n# Save the annotated CSV file\ndf.to_csv(output_csv, index=False)\n\nprint(f\"Processed comments saved to {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:30:30.177639Z","iopub.execute_input":"2024-12-02T04:30:30.178049Z","iopub.status.idle":"2024-12-02T04:31:30.399121Z","shell.execute_reply.started":"2024-12-02T04:30:30.178014Z","shell.execute_reply":"2024-12-02T04:31:30.397985Z"}},"outputs":[{"name":"stdout","text":"Processed comments saved to /kaggle/working/TRANSLATED_comments2.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}